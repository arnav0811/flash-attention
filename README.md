# flash-attention
Implementation of [Flash Attention](https://arxiv.org/pdf/2205.14135) in Triton and benchmarking against a naive PyTorch implementation.
